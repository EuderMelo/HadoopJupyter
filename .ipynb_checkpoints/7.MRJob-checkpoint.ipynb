{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dockermagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRJob\n",
    "\n",
    "- https://github.com/Yelp/mrjob\n",
    "- https://mrjob.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mrjob in /usr/local/lib/python3.9/site-packages (0.7.4)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.9/site-packages (from mrjob) (5.3.1)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# local install\n",
    "pip3 install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: mrjob: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/mrwordcount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/mrwordcount.py\n",
    "import re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "class MRWordCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            word = word.lower()\n",
    "            yield word,1\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "wget -q -c http://www.gutenberg.org/files/996/996-0.txt -O mrjob/donquixote.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"painted\"\t23\n",
      "\"painter\"\t11\n",
      "\"painters\"\t1\n",
      "\"painting\"\t8\n",
      "\"paints\"\t1\n",
      "\"pair\"\t45\n",
      "\"pairs\"\t3\n",
      "\"palace\"\t25\n",
      "\"palaces\"\t13\n",
      "\"palacios\"\t1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for local runner\n",
      "Creating temp directory /var/folders/x8/88k3_7f167g6x76m6hjxpq880000gn/T/mrwordcount.tiagoferreto.20210111.004849.291701\n",
      "Running step 1 of 1...\n",
      "job output is in /var/folders/x8/88k3_7f167g6x76m6hjxpq880000gn/T/mrwordcount.tiagoferreto.20210111.004849.291701/output\n",
      "Streaming final output from /var/folders/x8/88k3_7f167g6x76m6hjxpq880000gn/T/mrwordcount.tiagoferreto.20210111.004849.291701/output...\n",
      "Removing temp directory /var/folders/x8/88k3_7f167g6x76m6hjxpq880000gn/T/mrwordcount.tiagoferreto.20210111.004849.291701...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd mrjob\n",
    "\n",
    "# inline runner (default)\n",
    "# python3 mrwordcount.py donquixote.txt > donquixote-output.txt\n",
    "\n",
    "# local runner\n",
    "python3 mrwordcount.py -r local donquixote.txt > donquixote-output.txt\n",
    "\n",
    "# head output\n",
    "head donquixote-output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mrjob\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/fc28ab743aba16e90736ad4e29694bd2adaf7b879376ff149306d50c4e90/mrjob-0.7.4-py2.py3-none-any.whl (439kB)\n",
      "Collecting PyYAML>=3.10 (from mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Running setup.py bdist_wheel for PyYAML: started\n",
      "  Running setup.py bdist_wheel for PyYAML: finished with status 'done'\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, mrjob\n",
      "Successfully installed PyYAML-5.3.1 mrjob-0.7.4\n",
      "Collecting mrjob\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/fc28ab743aba16e90736ad4e29694bd2adaf7b879376ff149306d50c4e90/mrjob-0.7.4-py2.py3-none-any.whl (439kB)\n",
      "Collecting PyYAML>=3.10 (from mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Running setup.py bdist_wheel for PyYAML: started\n",
      "  Running setup.py bdist_wheel for PyYAML: finished with status 'done'\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, mrjob\n",
      "Successfully installed PyYAML-5.3.1 mrjob-0.7.4\n",
      "Collecting mrjob\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/fc28ab743aba16e90736ad4e29694bd2adaf7b879376ff149306d50c4e90/mrjob-0.7.4-py2.py3-none-any.whl (439kB)\n",
      "Collecting PyYAML>=3.10 (from mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Running setup.py bdist_wheel for PyYAML: started\n",
      "  Running setup.py bdist_wheel for PyYAML: finished with status 'done'\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, mrjob\n",
      "Successfully installed PyYAML-5.3.1 mrjob-0.7.4\n",
      "Collecting mrjob\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/58/fc28ab743aba16e90736ad4e29694bd2adaf7b879376ff149306d50c4e90/mrjob-0.7.4-py2.py3-none-any.whl (439kB)\n",
      "Collecting PyYAML>=3.10 (from mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Running setup.py bdist_wheel for PyYAML: started\n",
      "  Running setup.py bdist_wheel for PyYAML: finished with status 'done'\n",
      "  Stored in directory: /home/hadoop/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: PyYAML, mrjob\n",
      "Successfully installed PyYAML-5.3.1 mrjob-0.7.4\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# install in hadoop cluster\n",
    "docker exec -u hadoop hadoop pip3 install mrjob\n",
    "docker exec -u hadoop hadoop1 pip3 install mrjob\n",
    "docker exec -u hadoop hadoop2 pip3 install mrjob\n",
    "docker exec -u hadoop hadoop3 pip3 install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "docker cp mrjob hadoop:/opt\n",
    "docker exec hadoop chown -R hadoop:hadoop /opt/mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-11 00:50:12,819 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 3.2.1\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar\n",
      "Creating temp directory /tmp/mrwordcount.hadoop.20210111.005013.668024\n",
      "uploading working dir files to hdfs:///user/hadoop/tmp/mrjob/mrwordcount.hadoop.20210111.005013.668024/files/wd...\n",
      "Copying other local files to hdfs:///user/hadoop/tmp/mrjob/mrwordcount.hadoop.20210111.005013.668024/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar6657991860716594815/] [] /tmp/streamjob7877810569761033444.jar tmpDir=null\n",
      "  Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "  Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "  Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "  Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "  Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1610315082616_0004\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Total input files to process : 1\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  number of splits:2\n",
      "  SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "  Submitting tokens for job: job_1610315082616_0004\n",
      "  Executing with tokens: []\n",
      "  resource-types.xml not found\n",
      "  Unable to find 'resource-types.xml'.\n",
      "  Submitted application application_1610315082616_0004\n",
      "  The url to track the job: http://hadoop:8088/proxy/application_1610315082616_0004/\n",
      "  Running job: job_1610315082616_0004\n",
      "  Job job_1610315082616_0004 running in uber mode : false\n",
      "   map 0% reduce 0%\n",
      "   map 100% reduce 0%\n",
      "   map 100% reduce 100%\n",
      "  Job job_1610315082616_0004 completed successfully\n",
      "  Output directory: hdfs:///user/hadoop/donquixote-output\n",
      "Counters: 54\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=2394958\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=204012\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=340735\n",
      "\t\tFILE: Number of bytes written=1374205\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=2395174\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\t\tHDFS: Number of bytes written=204012\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tData-local map tasks=2\n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=10034432\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1797376\n",
      "\t\tTotal time spent by all map tasks (ms)=39197\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=78394\n",
      "\t\tTotal time spent by all reduce tasks (ms)=7021\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=14042\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=39197\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=7021\n",
      "\tMap-Reduce Framework\n",
      "\t\tCPU time spent (ms)=15000\n",
      "\t\tCombine input records=435439\n",
      "\t\tCombine output records=23909\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tGC time elapsed (ms)=284\n",
      "\t\tInput split bytes=216\n",
      "\t\tMap input records=43281\n",
      "\t\tMap output bytes=3990544\n",
      "\t\tMap output materialized bytes=340741\n",
      "\t\tMap output records=435439\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tPeak Map Physical memory (bytes)=267132928\n",
      "\t\tPeak Map Virtual memory (bytes)=1912135680\n",
      "\t\tPeak Reduce Physical memory (bytes)=155697152\n",
      "\t\tPeak Reduce Virtual memory (bytes)=1922408448\n",
      "\t\tPhysical memory (bytes) snapshot=689324032\n",
      "\t\tReduce input groups=16444\n",
      "\t\tReduce input records=23909\n",
      "\t\tReduce output records=16444\n",
      "\t\tReduce shuffle bytes=340741\n",
      "\t\tShuffled Maps =2\n",
      "\t\tSpilled Records=47818\n",
      "\t\tTotal committed heap usage (bytes)=460849152\n",
      "\t\tVirtual memory (bytes) snapshot=5746671616\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "job output is in hdfs:///user/hadoop/donquixote-output\n",
      "Removing HDFS temp directory hdfs:///user/hadoop/tmp/mrjob/mrwordcount.hadoop.20210111.005013.668024...\n",
      "Removing temp directory /tmp/mrwordcount.hadoop.20210111.005013.668024...\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "cd /opt/mrjob\n",
    "\n",
    "# create directory in HDFS and send file\n",
    "hdfs dfs -mkdir donquixote\n",
    "hdfs dfs -put donquixote.txt donquixote\n",
    "\n",
    "# run in hadoop\n",
    "python3 mrwordcount.py -r hadoop --output-dir donquixote-output hdfs:///user/hadoop/donquixote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-11 00:51:50,311 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "\"0\"\t2\n",
      "\"000\"\t1\n",
      "\"1\"\t45\n",
      "\"104k\"\t1\n",
      "\"105k\"\t1\n",
      "\"106k\"\t1\n",
      "\"1085\"\t1\n",
      "\"108k\"\t1\n",
      "\"109k\"\t2\n",
      "\"10k\"\t1\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop -w /opt/mrjob hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "# get output\n",
    "hdfs dfs -getmerge donquixote-output donquixote-output.txt\n",
    "\n",
    "# head output\n",
    "head donquixote-output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- weblogs.csv\n",
    "- books from Gutenberg project\n",
    "- departments.csv and employees.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/1_count_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/1_count_weblog.py\n",
    "#Total number of times each page is visited\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRURLCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        #Extract site\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        #Emit url and 1\n",
    "        yield url, 1\n",
    "\n",
    "    def reducer(self, key, list_of_values):\n",
    "        yield key,sum(list_of_values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRURLCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/js/vendor/moment.min.js\"\t173\n",
      "\"/login.php\"\t3298\n",
      "\"/contestsubmit.php?id=43\"\t5\n",
      "\"/contestsubmit.php?id=44\"\t1\n",
      "\"/contestsubmit.php?id=45\"\t23\n",
      "\"/countdown.php\"\t1\n",
      "\"/countdown.php?name=Another%20Multiplication%20Game\"\t1\n",
      "\"/countdown.php?name=RUET%20OJ%20Server%20Testing%20Contest\"\t71\n",
      "\"/createadmin.php\"\t4\n",
      "\"/css/bootstrap.min.css\"\t404\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/1_count_weblog.py datasets/weblog.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/2_max_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/2_max_weblog.py\n",
    "# Return most visited URL\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRURLMax(MRJob) :\n",
    "\n",
    "    def mapper1(self, _, line) :\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        #Extract site\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        #Emit url and 1\n",
    "        yield url, 1\n",
    "\n",
    "    def reducer1(self, key, list_of_values) :\n",
    "        yield None, (sum(list_of_values), key)\n",
    "\n",
    "    def reducer2(self, key, list_of_values) :\n",
    "        yield max(list_of_values)\n",
    "\n",
    "    def steps(self) :\n",
    "        return [MRStep(mapper=self.mapper1, reducer=self.reducer1),\n",
    "        MRStep(reducer=self.reducer2)]\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    MRURLMax.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298\t\"/login.php\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/2_max_weblog.py datasets/weblog.csv 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/3_average_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/3_average_weblog.py\n",
    "#Average visit time\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRAvgVisitTime(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = float(data[4].strip())\n",
    "\n",
    "        #Extract site\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        #Emit url and visit time\n",
    "        yield url, visit\n",
    "\n",
    "    def reducer(self, key, list_of_values):\n",
    "        count = 0\n",
    "        total = 0.0\n",
    "        for x in list_of_values:\n",
    "            total = total + x\n",
    "            count = count + 1\n",
    "\n",
    "        avglen = (\"%.2f\" % (total/count))\n",
    "        yield key,avglen\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRAvgVisitTime.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/js/vendor/moment.min.js\"\t\"279.61\"\n",
      "\"/login.php\"\t\"252.70\"\n",
      "\"/css/bootstrap.min.css.map\"\t\"25.87\"\n",
      "\"/css/font-awesome.min.css\"\t\"256.18\"\n",
      "\"/css/main.css\"\t\"240.80\"\n",
      "\"/css/normalize.css\"\t\"228.38\"\n",
      "\"/css/style.css\"\t\"261.45\"\n",
      "\"/dboot/js/bootstrap.min.js\"\t\"428.69\"\n",
      "\"/dcss/bootstrap-datetimepicker.min.css\"\t\"103.50\"\n",
      "\"/description.php\"\t\"117.08\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/3_average_weblog.py datasets/weblog.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/4_topn_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/4_topn_weblog.py\n",
    "#Top 3 visited pages\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MRTopN(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        #Extract url\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        #Emit url and 1\n",
    "        yield url, 1\n",
    "\n",
    "    def reducer1(self, key, list_of_values):\n",
    "        total_count = sum(list_of_values)\n",
    "        yield None, (total_count, key)\n",
    "\n",
    "    def reducer2(self, _, list_of_values):\n",
    "        N=3\n",
    "        list_of_values = sorted(list(list_of_values), reverse=True)\n",
    "        return list_of_values[:N]\n",
    "\n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.mapper, reducer=self.reducer1),\n",
    "        MRStep(reducer=self.reducer2)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRTopN.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298\t\"/login.php\"\n",
      "2653\t\"/home.php\"\n",
      "1417\t\"/js/vendor/modernizr-2.8.3.min.js\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/4_topn_weblog.py datasets/weblog.csv 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/5_filter_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/5_filter_weblog.py\n",
    "#Filter accesses to \"/login.php?value=fail\" on Feb/2018\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRFilter(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        #Extract site\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        #Extract month/year\n",
    "        date = time[4:12]\n",
    "\n",
    "        #Filter access to \"/login.php?value=fail\" on Feb/2018\n",
    "        if url == \"/login.php?value=fail\" and date == \"Feb/2018\" :\n",
    "            yield url, (time, ip, visit)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRFilter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/login.php?value=fail\"\t[\"[17/Feb/2018:20:08:56\", \"10.128.2.1\", \"185.3492762625749\"]\n",
      "\"/login.php?value=fail\"\t[\"[17/Feb/2018:20:20:28\", \"10.130.2.1\", \"231.88065750818035\"]\n",
      "\"/login.php?value=fail\"\t[\"[18/Feb/2018:19:40:31\", \"10.128.2.1\", \"119.2142303257265\"]\n",
      "\"/login.php?value=fail\"\t[\"[18/Feb/2018:19:40:35\", \"10.128.2.1\", \"147.46020967961022\"]\n",
      "\"/login.php?value=fail\"\t[\"[18/Feb/2018:19:40:38\", \"10.131.0.1\", \"257.82366658285235\"]\n",
      "\"/login.php?value=fail\"\t[\"[18/Feb/2018:19:40:39\", \"10.131.0.1\", \"169.11496206962957\"]\n",
      "\"/login.php?value=fail\"\t[\"[20/Feb/2018:11:14:24\", \"10.130.2.1\", \"330.90262403457416\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:02\", \"10.131.0.1\", \"766.0191400216718\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:08\", \"10.128.2.1\", \"34.905177651134075\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:10\", \"10.128.2.1\", \"49.17624847339196\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:11\", \"10.128.2.1\", \"268.1915691580601\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:33\", \"10.130.2.1\", \"68.96655453836624\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:26:38\", \"10.130.2.1\", \"35.34159176564747\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:30:04\", \"10.130.2.1\", \"132.7902384183176\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:30:08\", \"10.130.2.1\", \"181.43019268284462\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:06:30:13\", \"10.130.2.1\", \"140.19336438252802\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:12:43:05\", \"10.128.2.1\", \"191.28279631322528\"]\n",
      "\"/login.php?value=fail\"\t[\"[22/Feb/2018:12:43:13\", \"10.128.2.1\", \"54.3434972757474\"]\n",
      "\"/login.php?value=fail\"\t[\"[25/Feb/2018:13:34:22\", \"10.128.2.1\", \"385.5021656353063\"]\n",
      "\"/login.php?value=fail\"\t[\"[25/Feb/2018:17:25:11\", \"10.128.2.1\", \"36.92692421159084\"]\n",
      "\"/login.php?value=fail\"\t[\"[26/Feb/2018:03:55:24\", \"10.130.2.1\", \"390.67091933717063\"]\n",
      "\"/login.php?value=fail\"\t[\"[26/Feb/2018:03:55:56\", \"10.131.0.1\", \"113.72912981897535\"]\n",
      "\"/login.php?value=fail\"\t[\"[26/Feb/2018:03:56:01\", \"10.131.0.1\", \"180.1077939718322\"]\n",
      "\"/login.php?value=fail\"\t[\"[26/Feb/2018:03:56:03\", \"10.131.0.1\", \"60.35491691867254\"]\n",
      "\"/login.php?value=fail\"\t[\"[26/Feb/2018:03:56:04\", \"10.131.0.1\", \"305.96401522218554\"]\n",
      "\"/login.php?value=fail\"\t[\"[28/Feb/2018:03:44:51\", \"10.130.2.1\", \"106.17974660973063\"]\n",
      "\"/login.php?value=fail\"\t[\"[28/Feb/2018:20:47:32\", \"10.130.2.1\", \"555.7294064467495\"]\n",
      "\"/login.php?value=fail\"\t[\"[28/Feb/2018:20:47:50\", \"10.131.0.1\", \"26.838604094485987\"]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/5_filter_weblog.py datasets/weblog.csv 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/6_distinct_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/6_distinct_weblog.py\n",
    "#Distinct IPs\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRDistinct(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        yield ip, None\n",
    "\n",
    "    def reducer(self, key, list_of_values) :\n",
    "        yield key, None\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRDistinct.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"10.131.0.1\"\tnull\n",
      "\"10.131.2.1\"\tnull\n",
      "\"10.129.2.1\"\tnull\n",
      "\"10.130.2.1\"\tnull\n",
      "\"10.128.2.1\"\tnull\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/6_distinct_weblog.py datasets/weblog.csv 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/7_binning_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/7_binning_weblog.py\n",
    "#Create bins for different status codes for 20/Feb/2018\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRBinning(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "        \n",
    "        #Extract month/year\n",
    "        date = time[1:12]\n",
    "\n",
    "        #Filter accesses on 20/Feb/2018\n",
    "        if date == \"20/Feb/2018\" :\n",
    "            yield status, (time, request, ip)\n",
    "\n",
    "    def reducer(self, key, list_of_values):\n",
    "        yield key, (list(list_of_values))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRBinning.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"304\"\t[[\"[20/Feb/2018:09:23:18\", \"GET /css/bootstrap.min.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /css/font-awesome.min.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /css/normalize.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /css/main.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /css/style.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:09:23:18\", \"GET /js/vendor/jquery-1.12.0.min.js HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:19\", \"GET /bootstrap-3.3.7/js/bootstrap.min.js HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:09:23:31\", \"GET /js/vendor/moment.min.js HTTP/1.1\", \"10.128.2.1\"]]\n",
      "\"404\"\t[[\"[20/Feb/2018:01:48:55\", \"GET /robots.txt HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:13:58:09\", \"GET /robots.txt HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:16:08:45\", \"GET /robots.txt HTTP/1.1\", \"10.130.2.1\"]]\n",
      "\"302\"\t[[\"[20/Feb/2018:01:50:40\", \"GET / HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:07:05:37\", \"GET / HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:17\", \"GET / HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:29\", \"POST /process.php HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:04:14\", \"GET / HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:11:13:54\", \"GET / HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:11:14:24\", \"POST /process.php HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:13:34:15\", \"GET / HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:13:58:13\", \"GET / HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET / HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:16:09:18\", \"GET / HTTP/1.1\", \"10.130.2.1\"]]\n",
      "\"200\"\t[[\"[20/Feb/2018:01:51:41\", \"GET /login.php HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:07:06:12\", \"GET /login.php HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:09:23:17\", \"GET /login.php HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:21\", \"GET /fonts/fontawesome-webfont.woff2?v=4.6.3 HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:29\", \"GET /home.php HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:09:23:30\", \"GET /bootstrap-3.3.7/js/bootstrap.js HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:09:24:12\", \"GET /compiler.php HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:11:04:47\", \"GET /login.php HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:04:51\", \"GET /css/bootstrap.min.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:04:52\", \"GET /css/normalize.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:04:55\", \"GET /css/font-awesome.min.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:04:57\", \"GET /css/main.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:04:58\", \"GET /css/style.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:13:54\", \"GET /login.php HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:11:13:55\", \"GET /css/bootstrap.min.css HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:11:13:55\", \"GET /css/font-awesome.min.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:13:55\", \"GET /css/normalize.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:13:55\", \"GET /css/main.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:13:56\", \"GET /css/style.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:13:56\", \"GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:13:56\", \"GET /js/vendor/jquery-1.12.0.min.js HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:11:13:56\", \"GET /bootstrap-3.3.7/js/bootstrap.min.js HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:11:14:24\", \"GET /login.php?value=fail HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:13:34:44\", \"GET /login.php HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:13:58:18\", \"GET /login.php HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /login.php HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/font-awesome.min.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/bootstrap.min.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /js/vendor/jquery-1.12.0.min.js HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/style.css HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /bootstrap-3.3.7/js/bootstrap.min.js HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/main.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1\", \"10.131.0.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /js/vendor/modernizr-2.8.3.min.js HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/normalize.css HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /img/ruet.png HTTP/1.1\", \"10.130.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /css/normalize.css HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:14:38:25\", \"GET /fonts/fontawesome-webfont.woff?v=4.6.3 HTTP/1.1\", \"10.128.2.1\"], [\"[20/Feb/2018:16:09:54\", \"GET /login.php HTTP/1.1\", \"10.130.2.1\"]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/7_binning_weblog.py datasets/weblog.csv 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/8_invertedindex_books.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/8_invertedindex_books.py\n",
    "#Inverted Index\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class MRInvertedIndex(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        fileName = os.environ['mapreduce_map_input_file']\n",
    "\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            yield word, fileName\n",
    "\n",
    "    def reducer(self, key, list_of_values):\n",
    "        docs = set()\n",
    "        for x in list_of_values :\n",
    "            docs.add(x)\n",
    "        yield key,list(docs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRInvertedIndex.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"one's\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one),\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one,\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one,\\\"\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one,\\u201d\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one--and\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one--tell\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one--the\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one-and-twenty.\\u201d\"\t[\"file://datasets/books/book1.txt\"]\n",
      "\"one-armed\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one-half\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one-handed\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one-legged\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one-sided\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one-third\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one.\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one.\\\"\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one.\\u201d\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one:\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one;\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one?\"\t[\"file://datasets/books/book1.txt\"]\n",
      "\"one?\\\"\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one?\\u201d\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one\\\"--he\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one\\u2014I\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one\\u2014had\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one\\u2014so\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"one\\u2019s\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"one_,\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"one_.)\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"oneness,\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"ones\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"ones,\"\t[\"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"ones,\\\"\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"ones,\\u201d\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"ones.\"\t[\"file://datasets/books/book1.txt\", \"file://datasets/books/book3.txt\", \"file://datasets/books/book2.txt\"]\n",
      "\"ones;\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"ones\\\"--with\"\t[\"file://datasets/books/book3.txt\"]\n",
      "\"ones\\u2014probably\"\t[\"file://datasets/books/book2.txt\"]\n",
      "\"oneself\"\t[\"file://datasets/books/book2.txt\"]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/8_invertedindex_books.py datasets/books 2> /dev/null | head -n 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/9_sort_weblog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/9_sort_weblog.py\n",
    "# Sort visit times in descending order\n",
    "from mrjob.job import MRJob\n",
    "class MRSortVisit(MRJob) :\n",
    "    def mapper(self, _, line):\n",
    "        #Split the line with comma separated fields\n",
    "        data = line.split(',')\n",
    "\n",
    "        #Parse line\n",
    "        ip = data[0].strip()\n",
    "        #Check if it's not the header line\n",
    "        if ip == 'IP' : return\n",
    "        time = data[1].strip()\n",
    "        request = data[2].strip()\n",
    "        status = data[3].strip()\n",
    "        visit = data[4].strip()\n",
    "\n",
    "        #Extract site\n",
    "        url = request.split(' ')[1]\n",
    "\n",
    "        yield None, (visit, (time, url, ip))\n",
    "\n",
    "    def reducer(self, key, list_of_values):\n",
    "        l = [(float(v), content) for v, content in list_of_values]\n",
    "        l.sort(reverse=True)\n",
    "        return l\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRSortVisit.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8742.057189992775\t[\"[29/Jan/2018:20:33:45\", \"/login.php\", \"10.128.2.1\"]\n",
      "6287.629575490433\t[\"[29/Jan/2018:20:55:42\", \"/login.php\", \"10.128.2.1\"]\n",
      "5711.326270236046\t[\"[29/Jan/2018:20:35:56\", \"/js/vendor/modernizr-2.8.3.min.js\", \"10.128.2.1\"]\n",
      "5283.59276598012\t[\"[09/Nov/2017:19:53:43\", \"/js/vendor/modernizr-2.8.3.min.js\", \"10.131.0.1\"]\n",
      "5123.493680523937\t[\"[29/Jan/2018:20:47:45\", \"/js/vendor/modernizr-2.8.3.min.js\", \"10.128.2.1\"]\n",
      "5053.873518356491\t[\"[13/Nov/2017:09:11:14\", \"/login.php\", \"10.131.2.1\"]\n",
      "4642.003763780086\t[\"[29/Jan/2018:20:29:30\", \"/js/vendor/modernizr-2.8.3.min.js\", \"10.131.0.1\"]\n",
      "4615.5689039456365\t[\"[29/Jan/2018:20:32:40\", \"/login.php\", \"10.128.2.1\"]\n",
      "4421.817090530212\t[\"[29/Jan/2018:20:35:37\", \"/js/vendor/modernizr-2.8.3.min.js\", \"10.131.0.1\"]\n",
      "3857.8085677731\t[\"[24/Nov/2017:08:29:49\", \"/css/font-awesome.min.css\", \"10.131.2.1\"]\n",
      "3725.3713482396056\t[\"[29/Jan/2018:20:34:22\", \"/login.php\", \"10.131.0.1\"]\n",
      "3667.904220839362\t[\"[12/Nov/2017:19:44:01\", \"/archive.php\", \"10.130.2.1\"]\n",
      "3570.29271074942\t[\"[29/Jan/2018:20:29:30\", \"/login.php\", \"10.131.0.1\"]\n",
      "3485.9893149824265\t[\"[29/Jan/2018:20:35:33\", \"/login.php\", \"10.131.0.1\"]\n",
      "3473.156110992622\t[\"[23/Nov/2017:18:35:44\", \"/css/main.css\", \"10.128.2.1\"]\n",
      "3471.1054516357603\t[\"[30/Nov/2017:19:47:30\", \"/robots.txt\", \"10.131.0.1\"]\n",
      "3356.568134399352\t[\"[14/Dec/2017:11:13:28\", \"/css/font-awesome.min.css\", \"10.131.0.1\"]\n",
      "3214.708818153326\t[\"[29/Jan/2018:20:22:42\", \"/css/bootstrap.min.css\", \"10.130.2.1\"]\n",
      "3207.5925234924525\t[\"[30/Nov/2017:13:25:50\", \"/archive.php?page=2\", \"10.129.2.1\"]\n",
      "3202.8604736680045\t[\"[29/Nov/2017:17:55:01\", \"/css/style.css\", \"10.129.2.1\"]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/9_sort_weblog.py datasets/weblog.csv 2> /dev/null | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InnerJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/10_innerjoin_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/10_innerjoin_db.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class MRInnerJoin(MRJob) :\n",
    "    def mapper(self, _, line):\n",
    "        data = line.split(',')\n",
    "\n",
    "        filename = os.environ['mapreduce_map_input_file']\n",
    "\n",
    "        if 'employees.csv' in filename :\n",
    "            dep_no = data[2]\n",
    "            yield dep_no, ('Employee', data)\n",
    "        elif 'departments.csv' in filename:\n",
    "            dep_no = data[0]\n",
    "            yield dep_no, ('Department', data)\n",
    "\n",
    "    def reducer(self, key, list_of_values) :\n",
    "        values = list(list_of_values)\n",
    "        employees = []\n",
    "        departments = []\n",
    "        for v in values:\n",
    "            if v[0] == 'Employee' :\n",
    "                employees.append(v)\n",
    "            elif v[0] == 'Department' :\n",
    "                departments.append(v)\n",
    "\n",
    "        # Inner Join\n",
    "        for e in employees :\n",
    "            for d in departments :\n",
    "                yield key, (e+d)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    MRInnerJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"d005\"\t[\"Employee\", [\"10001\", \"Georgi Facello\", \"d005\", \"1986-06-26\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10006\", \"Anneke Preusig\", \"d005\", \"1989-06-02\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10008\", \"Saniya Kalloufi\", \"d005\", \"1994-09-15\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10012\", \"Patricio Bridgland\", \"d005\", \"1992-12-18\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10014\", \"Berni Genin\", \"d005\", \"1987-03-11\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10018\", \"Kazuhide Peha\", \"d005\", \"1987-04-03\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10021\", \"Ramzi Erde\", \"d005\", \"1988-02-10\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10022\", \"Shahaf Famili\", \"d005\", \"1995-08-22\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10023\", \"Bojan Montemayor\", \"d005\", \"1989-12-17\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10025\", \"Prasadram Heyers\", \"d005\", \"1987-08-17\"], \"Department\", [\"d005\", \"Development\"]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/10_innerjoin_db.py datasets/employees.csv datasets/departments.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeftOuterJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/11_leftouterjoin_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/11_leftouterjoin_db.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class MRLeftOuterJoin(MRJob) :\n",
    "    def mapper(self, _, line):\n",
    "        data = line.split(',')\n",
    "\n",
    "        filename = os.environ['mapreduce_map_input_file']\n",
    "\n",
    "        if 'employees.csv' in filename :\n",
    "            dep_no = data[2]\n",
    "            yield dep_no, ('Employee', data)\n",
    "        elif 'departments.csv' in filename:\n",
    "            dep_no = data[0]\n",
    "            yield dep_no, ('Department', data)\n",
    "\n",
    "    def reducer(self, key, list_of_values) :\n",
    "        # yield None, list(list_of_values)\n",
    "        values = list(list_of_values)\n",
    "        employees = []\n",
    "        departments = []\n",
    "        for v in values:\n",
    "            if v[0] == 'Employee' :\n",
    "                employees.append(v)\n",
    "            elif v[0] == 'Department' :\n",
    "                departments.append(v)\n",
    "\n",
    "        # Left Outer Join\n",
    "        for e in employees :\n",
    "            if len(departments) > 0 :\n",
    "                for d in departments :\n",
    "                    yield key, (e+d)\n",
    "            else :\n",
    "                yield key, (e)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    MRLeftOuterJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"d005\"\t[\"Employee\", [\"10001\", \"Georgi Facello\", \"d005\", \"1986-06-26\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10006\", \"Anneke Preusig\", \"d005\", \"1989-06-02\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10008\", \"Saniya Kalloufi\", \"d005\", \"1994-09-15\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10012\", \"Patricio Bridgland\", \"d005\", \"1992-12-18\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10014\", \"Berni Genin\", \"d005\", \"1987-03-11\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10018\", \"Kazuhide Peha\", \"d005\", \"1987-04-03\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10021\", \"Ramzi Erde\", \"d005\", \"1988-02-10\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10022\", \"Shahaf Famili\", \"d005\", \"1995-08-22\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10023\", \"Bojan Montemayor\", \"d005\", \"1989-12-17\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10025\", \"Prasadram Heyers\", \"d005\", \"1987-08-17\"], \"Department\", [\"d005\", \"Development\"]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/11_leftouterjoin_db.py datasets/employees.csv datasets/departments.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RightOuterJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/12_rightouterjoin_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/12_rightouterjoin_db.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class MRRightOuterJoin(MRJob) :\n",
    "    def mapper(self, _, line):\n",
    "        data = line.split(',')\n",
    "\n",
    "        filename = os.environ['mapreduce_map_input_file']\n",
    "        \n",
    "        if 'employees.csv' in filename :\n",
    "            dep_no = data[2]\n",
    "            yield dep_no, ('Employee', data)\n",
    "        elif 'departments.csv' in filename:\n",
    "            dep_no = data[0]\n",
    "            yield dep_no, ('Department', data)\n",
    "\n",
    "    def reducer(self, key, list_of_values) :\n",
    "        # yield None, list(list_of_values)\n",
    "        values = list(list_of_values)\n",
    "        employees = []\n",
    "        departments = []\n",
    "        for v in values:\n",
    "            if v[0] == 'Employee' :\n",
    "                employees.append(v)\n",
    "            elif v[0] == 'Department' :\n",
    "                departments.append(v)\n",
    "\n",
    "        # Right Outer Join\n",
    "        for d in departments :\n",
    "            if len(employees) > 0 :\n",
    "                for e in employees :\n",
    "                    yield key, (e+d)\n",
    "            else :\n",
    "                yield key, (d)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    MRRightOuterJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"d005\"\t[\"Employee\", [\"10001\", \"Georgi Facello\", \"d005\", \"1986-06-26\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10006\", \"Anneke Preusig\", \"d005\", \"1989-06-02\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10008\", \"Saniya Kalloufi\", \"d005\", \"1994-09-15\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10012\", \"Patricio Bridgland\", \"d005\", \"1992-12-18\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10014\", \"Berni Genin\", \"d005\", \"1987-03-11\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10018\", \"Kazuhide Peha\", \"d005\", \"1987-04-03\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10021\", \"Ramzi Erde\", \"d005\", \"1988-02-10\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10022\", \"Shahaf Famili\", \"d005\", \"1995-08-22\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10023\", \"Bojan Montemayor\", \"d005\", \"1989-12-17\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10025\", \"Prasadram Heyers\", \"d005\", \"1987-08-17\"], \"Department\", [\"d005\", \"Development\"]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/12_rightouterjoin_db.py datasets/employees.csv datasets/departments.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FullOuterJoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mrjob/13_fullouterjoin_db.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mrjob/13_fullouterjoin_db.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "\n",
    "class MRFullOuterJoin(MRJob) :\n",
    "    def mapper(self, _, line):\n",
    "        data = line.split(',')\n",
    "\n",
    "        filename = os.environ['mapreduce_map_input_file']\n",
    "\n",
    "        if 'employees.csv' in filename :\n",
    "            dep_no = data[2]\n",
    "            yield dep_no, ('Employee', data)\n",
    "        elif 'departments.csv' in filename:\n",
    "            dep_no = data[0]\n",
    "            yield dep_no, ('Department', data)\n",
    "\n",
    "    def reducer(self, key, list_of_values) :\n",
    "        values = list(list_of_values)\n",
    "        employees = []\n",
    "        departments = []\n",
    "        for v in values:\n",
    "            if v[0] == 'Employee' :\n",
    "                employees.append(v)\n",
    "            elif v[0] == 'Department' :\n",
    "                departments.append(v)\n",
    "\n",
    "        # Full Outer Join\n",
    "        if len(employees) > 0 :\n",
    "            for e in employees :\n",
    "                if len(departments) > 0 :\n",
    "                    for d in departments :\n",
    "                        yield key, (e+d)\n",
    "                else :\n",
    "                    yield key, (e)\n",
    "        else :\n",
    "            yield None, (d)\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    MRFullOuterJoin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"d005\"\t[\"Employee\", [\"10001\", \"Georgi Facello\", \"d005\", \"1986-06-26\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10006\", \"Anneke Preusig\", \"d005\", \"1989-06-02\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10008\", \"Saniya Kalloufi\", \"d005\", \"1994-09-15\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10012\", \"Patricio Bridgland\", \"d005\", \"1992-12-18\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10014\", \"Berni Genin\", \"d005\", \"1987-03-11\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10018\", \"Kazuhide Peha\", \"d005\", \"1987-04-03\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10021\", \"Ramzi Erde\", \"d005\", \"1988-02-10\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10022\", \"Shahaf Famili\", \"d005\", \"1995-08-22\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10023\", \"Bojan Montemayor\", \"d005\", \"1989-12-17\"], \"Department\", [\"d005\", \"Development\"]]\n",
      "\"d005\"\t[\"Employee\", [\"10025\", \"Prasadram Heyers\", \"d005\", \"1987-08-17\"], \"Department\", [\"d005\", \"Development\"]]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python3 mrjob/13_fullouterjoin_db.py datasets/employees.csv datasets/departments.csv 2> /dev/null | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
