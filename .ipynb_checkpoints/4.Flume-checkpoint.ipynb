{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dockermagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flume\n",
    "![Flume](https://flume.apache.org/_static/flume-logo.png)\n",
    "\n",
    "- https://flume.apache.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- download from https://flume.apache.org/download.html\n",
    "- version 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download package\n",
    "wget -q -c https://downloads.apache.org/flume/1.9.0/apache-flume-1.9.0-bin.tar.gz\n",
    "\n",
    "# Copy installation package to container\n",
    "docker cp apache-flume-1.9.0-bin.tar.gz hadoop:/opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "\n",
    "# unpack file and create link\n",
    "tar -zxf /opt/apache-flume-1.9.0-bin.tar.gz -C /opt\n",
    "ln -s /opt/apache-flume-1.9.0-bin /opt/flume\n",
    "\n",
    "# update guava library on Flume\n",
    "rm -f /opt/flume/lib/guava-11.0.2.jar \n",
    "cp -f /opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /opt/flume/lib\n",
    "\n",
    "# update envvars.sh\n",
    "cat >> /opt/envvars.sh << EOF\n",
    "# Flume\n",
    "export FLUME_HOME=/opt/flume\n",
    "export PATH=\\$PATH:\\$FLUME_HOME/bin\n",
    "\n",
    "EOF\n",
    "\n",
    "sudo rm /opt/apache-flume-1.9.0-bin.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tailagent example\n",
    "\n",
    "- https://flume.apache.org/releases/content/1.9.0/FlumeUserGuide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "# create tailagent.conf\n",
    "cat > $FLUME_HOME/conf/tailagent.conf << EOF\n",
    "# Agent components\n",
    "tailagent.sources = execsource\n",
    "tailagent.channels = memchannel\n",
    "tailagent.sinks = hdfssink\n",
    "\n",
    "# Configuring source\n",
    "tailagent.sources.execsource.type = exec\n",
    "tailagent.sources.execsource.command = tail -F /tmp/events\n",
    "\n",
    "# Configuring sink\n",
    "tailagent.sinks.hdfssink.type = hdfs\n",
    "tailagent.sinks.hdfssink.hdfs.path = /tmp\n",
    "tailagent.sinks.hdfssink.hdfs.filePrefix = tailevents-\n",
    "tailagent.sinks.hdfssink.hdfs.fileType = DataStream\n",
    "\n",
    "# Configuring channel\n",
    "tailagent.channels.memchannel.type = memory\n",
    "\n",
    "# Bind the source and sink to the channel \n",
    "tailagent.sources.execsource.channels = memchannel\n",
    "tailagent.sinks.hdfssink.channel = memchannel\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UID        PID  PPID  C STIME TTY          TIME CMD\n",
      "hadoop   10516 10510  0 22:19 ?        00:00:00 /bin/bash /opt/flume/bin/flume-ng agent -n tailagent -c ./conf -f ./conf/tailagent.conf\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "# run agent in background\n",
    "cd /opt/flume\n",
    "nohup flume-ng agent -n tailagent -c ./conf \\\n",
    "-f ./conf/tailagent.conf > ./tailagent.output 2>&1 &\n",
    "echo $! > ./tailagent.pid\n",
    "\n",
    "ps -fp $(cat ./tailagent.pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "\n",
    "# run random generator in background\n",
    "cd /opt/flume\n",
    "while true; do echo $RANDOM >> /tmp/events; sleep 1; done &\n",
    "echo $! > ./randomgen.pid\n",
    "disown %1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   2 hadoop supergroup         58 2021-01-10 22:20 /tmp/tailevents-.1610317196676\n",
      "-rw-r--r--   2 hadoop supergroup         56 2021-01-10 22:20 /tmp/tailevents-.1610317196677\n",
      "-rw-r--r--   2 hadoop supergroup         56 2021-01-10 22:20 /tmp/tailevents-.1610317196678\n",
      "-rw-r--r--   2 hadoop supergroup         58 2021-01-10 22:20 /tmp/tailevents-.1610317196679\n",
      "-rw-r--r--   2 hadoop supergroup         56 2021-01-10 22:20 /tmp/tailevents-.1610317196680\n",
      "-rw-r--r--   2 hadoop supergroup         56 2021-01-10 22:20 /tmp/tailevents-.1610317196681\n",
      "-rw-r--r--   2 hadoop supergroup          0 2021-01-10 22:20 /tmp/tailevents-.1610317196682.tmp\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "# check files generated in HDFS\n",
    "hdfs dfs -ls /tmp/tailevents*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-10 22:20:46,543 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "32719\n",
      "10482\n",
      "110\n",
      "24784\n",
      "16871\n",
      "27600\n",
      "27711\n",
      "28110\n",
      "14724\n",
      "20485\n",
      "2021-01-10 22:20:46,871 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "3753\n",
      "7063\n",
      "23118\n",
      "14781\n",
      "19959\n",
      "13979\n",
      "11058\n",
      "1944\n",
      "18707\n",
      "4090\n",
      "9301\n",
      "24316\n",
      "5406\n",
      "28845\n",
      "8926\n",
      "7828\n",
      "17084\n",
      "32219\n",
      "22451\n",
      "18105\n",
      "18468\n",
      "27422\n",
      "14026\n",
      "5063\n",
      "11698\n",
      "10843\n",
      "16120\n",
      "13702\n",
      "5822\n",
      "14653\n",
      "2891\n",
      "6160\n",
      "29513\n",
      "24807\n",
      "584\n",
      "20909\n",
      "24327\n",
      "32624\n",
      "13137\n",
      "15788\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "\n",
    "# cat files\n",
    "hdfs dfs -cat /tmp/tailevents*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /tmp/tailevents-.1610317196676\n",
      "Deleted /tmp/tailevents-.1610317196677\n",
      "Deleted /tmp/tailevents-.1610317196678\n",
      "Deleted /tmp/tailevents-.1610317196679\n",
      "Deleted /tmp/tailevents-.1610317196680\n",
      "Deleted /tmp/tailevents-.1610317196681\n",
      "Deleted /tmp/tailevents-.1610317196682\n",
      "Deleted /tmp/tailevents-.1610317196683.tmp\n"
     ]
    }
   ],
   "source": [
    "%%dockerexec -u hadoop hadoop\n",
    "source /opt/envvars.sh\n",
    "cd /opt/flume\n",
    "\n",
    "# kill random generator\n",
    "kill $(cat randomgen.pid)\n",
    "rm randomgen.pid\n",
    "\n",
    "# kill tailagent\n",
    "kill $(cat tailagent.pid)\n",
    "rm tailagent.pid\n",
    "rm tailagent.output\n",
    "\n",
    "# remove files\n",
    "hdfs dfs -rm /tmp/tailevents*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
