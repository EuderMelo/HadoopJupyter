{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pig\n",
    "![Pig](https://pig.apache.org/images/pig-logo.gif)\n",
    "\n",
    "- https://pig.apache.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- version 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64\n",
      "export PDSH_RCMD_TYPE=ssh\n",
      "\n",
      "export HADOOP_HOME=/opt/hadoop\n",
      "export HADOOP_COMMON_HOME=${HADOOP_HOME}\n",
      "export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop\n",
      "export HADOOP_HDFS_HOME=${HADOOP_HOME}\n",
      "export HADOOP_MAPRED_HOME=${HADOOP_HOME}\n",
      "export HADOOP_YARN_HOME=${HADOOP_HOME}\n",
      "\n",
      "export PATH=${PATH}:${HADOOP_HOME}/bin:${HADOOP_HOME}/sbin     \n",
      "\n",
      "# Flume\n",
      "export FLUME_HOME=/opt/flume\n",
      "export PATH=${PATH}:${FLUME_HOME}/bin\n",
      "\n",
      "# Sqoop\n",
      "export SQOOP_HOME=/opt/sqoop\n",
      "export PATH=${PATH}:${SQOOP_HOME}/bin\n",
      "\n",
      "# Pig\n",
      "export PIG_HOME=/opt/pig\n",
      "export PATH=${PATH}:${PIG_HOME}/bin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Download package\n",
    "cd /opt/pkgs\n",
    "wget -q -c https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n",
    "\n",
    "# unpack file and create link\n",
    "tar -zxf pig-0.17.0.tar.gz -C /opt\n",
    "ln -s /opt/pig-0.17.0 /opt/pig\n",
    "\n",
    "# update envvars.sh\n",
    "cat >> /opt/envvars.sh << EOF\n",
    "# Pig\n",
    "export PIG_HOME=/opt/pig\n",
    "export PATH=\\${PATH}:\\${PIG_HOME}/bin\n",
    "\n",
    "EOF\n",
    "\n",
    "cat /opt/envvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HOSTNAME': 'hadoop',\n",
       " 'OLDPWD': '/',\n",
       " 'PWD': '/opt',\n",
       " 'HOME': '/home/hadoop',\n",
       " 'SHELL': '/bin/bash',\n",
       " 'SHLVL': '1',\n",
       " 'PATH': '/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hadoop/sbin:/opt/flume/bin:/opt/sqoop/bin:/opt/pig/bin',\n",
       " '_': '/usr/bin/nohup',\n",
       " 'LANGUAGE': 'en.UTF-8',\n",
       " 'LANG': 'en.UTF-8',\n",
       " 'JPY_PARENT_PID': '1566',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline',\n",
       " 'JAVA_HOME': '/usr/lib/jvm/java-1.8.0-openjdk-amd64',\n",
       " 'PDSH_RCMD_TYPE': 'ssh',\n",
       " 'HADOOP_HOME': '/opt/hadoop',\n",
       " 'HADOOP_COMMON_HOME': '/opt/hadoop',\n",
       " 'HADOOP_CONF_DIR': '/opt/hadoop/etc/hadoop',\n",
       " 'HADOOP_HDFS_HOME': '/opt/hadoop',\n",
       " 'HADOOP_MAPRED_HOME': '/opt/hadoop',\n",
       " 'HADOOP_YARN_HOME': '/opt/hadoop',\n",
       " 'FLUME_HOME': '/opt/flume',\n",
       " 'SQOOP_HOME': '/opt/sqoop',\n",
       " 'PIG_HOME': '/opt/pig'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o /opt/envvars.sh\n",
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,San Jose Diridon Caltrain Station,37.329732,-121.901782,27,San Jose,8/6/2013\n",
      "3,San Jose Civic Center,37.330698,-121.888979,15,San Jose,8/5/2013\n",
      "4,Santa Clara at Almaden,37.333988,-121.894902,11,San Jose,8/6/2013\n",
      "5,Adobe on Almaden,37.331415,-121.8932,19,San Jose,8/5/2013\n",
      "6,San Pedro Square,37.336721,-121.894074,15,San Jose,8/7/2013\n",
      "7,Paseo de San Antonio,37.333798,-121.886943,15,San Jose,8/7/2013\n",
      "8,San Salvador at 1st,37.330165,-121.885831,15,San Jose,8/5/2013\n",
      "9,Japantown,37.348742,-121.894715,15,San Jose,8/5/2013\n",
      "10,San Jose City Hall,37.337391,-121.886995,15,San Jose,8/6/2013\n",
      "11,MLK Library,37.335885,-121.88566,19,San Jose,8/6/2013\n",
      "12,SJSU 4th at San Carlos,37.332808,-121.883891,19,San Jose,8/7/2013\n",
      "13,St James Park,37.339301,-121.889937,15,San Jose,8/6/2013\n",
      "14,Arena Green / SAP Center,37.332692,-121.900084,19,San Jose,8/5/2013\n",
      "16,SJSU - San Salvador at 9th,37.333955,-121.877349,15,San Jose,8/7/2013\n",
      "21,Franklin at Maple,37.481758,-122.226904,15,Redwood City,8/12/2013\n",
      "22,Redwood City Caltrain Station,37.48"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 14:31:59,735 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:32:05,611 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/datasets\n",
    "wget -q -c https://tinyurl.com/y5roz8kz -O stations.csv\n",
    "hdfs dfs -mkdir stations\n",
    "hdfs dfs -put stations.csv stations\n",
    "hdfs dfs -head stations/stations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grunt shell\n",
    "\n",
    "1. run in terminal (-x local => local execution)\n",
    "```\n",
    "source /opt/envvars.sh\n",
    "cd /opt/datasets\n",
    "pig -x local 2> /dev/null\n",
    "```\n",
    "2. \n",
    "```\n",
    "stations = LOAD 'stations.csv' USING PigStorage(',') AS \n",
    "(station_id:int, name:chararray, lat:float, long:float, \n",
    " dockcount:int, landmark:chararray, installation:chararray);\n",
    "```\n",
    "3. \n",
    "```\n",
    "station_ids_names = FOREACH stations GENERATE station_id, name;\n",
    "```\n",
    "4.\n",
    "```\n",
    "ordered = ORDER station_ids_names BY name;\n",
    "```\n",
    "\n",
    "5. \n",
    "```\n",
    "DESCRIBE stations;\n",
    "```\n",
    "6. \n",
    "```\n",
    "ILLUSTRATE ordered;\n",
    "```\n",
    "\n",
    "7. \n",
    "```\n",
    "DUMP ordered;\n",
    "```\n",
    "\n",
    "8. \n",
    "```\n",
    "QUIT;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 14:45:02,743 INFO pig.ExecTypeProvider: Trying ExecType : LOCAL\n",
      "2021-01-29 14:45:02,747 INFO pig.ExecTypeProvider: Trying ExecType : MAPREDUCE\n",
      "2021-01-29 14:45:02,748 INFO pig.ExecTypeProvider: Picked MAPREDUCE as the ExecType\n",
      "2021-01-29 14:45:02,908 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2021-01-29 14:45:02,908 [main] INFO  org.apache.pig.Main - Logging error messages to: /opt/src/pig_1611931502880.log\n",
      "2021-01-29 14:45:03,822 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /home/hadoop/.pigbootup not found\n",
      "2021-01-29 14:45:04,022 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2021-01-29 14:45:04,024 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://hadoop:9000\n",
      "2021-01-29 14:45:05,621 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-list_stations.pig-236f30ce-78ce-4d86-9970-fe479dfdb883\n",
      "2021-01-29 14:45:06,198 [main] INFO  org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl - Timeline service address: hadoop:8188\n",
      "2021-01-29 14:45:07,021 [main] INFO  org.apache.pig.backend.hadoop.PigATSClient - Created ATS Hook\n",
      "2021-01-29 14:45:07,100 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:09,674 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:10,421 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:10,748 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2021-01-29 14:45:11,049 [main] INFO  org.apache.pig.tools.pigstats.ScriptState - Pig features used in the script: ORDER_BY\n",
      "2021-01-29 14:45:11,253 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:11,277 [main] INFO  org.apache.pig.data.SchemaTupleBackend - Key [pig.schematuple] was not set... will not generate code.\n",
      "2021-01-29 14:45:11,396 [main] INFO  org.apache.pig.newplan.logical.optimizer.LogicalPlanOptimizer - {RULES_ENABLED=[AddForEach, ColumnMapKeyPrune, ConstantCalculator, GroupByConstParallelSetter, LimitOptimizer, LoadTypeCastInserter, MergeFilter, MergeForEach, NestedLimitOptimizer, PartitionFilterOptimizer, PredicatePushdownOptimizer, PushDownForEachFlatten, PushUpFilter, SplitFilter, StreamTypeCastInserter]}\n",
      "2021-01-29 14:45:11,463 [main] INFO  org.apache.pig.newplan.logical.rules.ColumnPruneVisitor - Columns pruned for stations: $2, $3, $4, $5, $6\n",
      "2021-01-29 14:45:11,608 [main] INFO  org.apache.pig.impl.util.SpillableMemoryManager - Selected heap (PS Old Gen) of size 699400192 to monitor. collectionUsageThreshold = 489580128, usageThreshold = 489580128\n",
      "2021-01-29 14:45:11,936 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MRCompiler - File concatenation threshold: 100 optimistic? false\n",
      "2021-01-29 14:45:12,195 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.SecondaryKeyOptimizerMR - Using Secondary Key Optimization for MapReduce node scope-14\n",
      "2021-01-29 14:45:12,258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size before optimization: 3\n",
      "2021-01-29 14:45:12,258 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MultiQueryOptimizer - MR plan size after optimization: 3\n",
      "2021-01-29 14:45:12,336 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:12,548 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:13,523 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:13,911 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2021-01-29 14:45:13,933 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2021-01-29 14:45:13,933 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2021-01-29 14:45:13,952 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2021-01-29 14:45:13,961 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2021-01-29 14:45:13,983 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2021-01-29 14:45:14,275 [Thread-8] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:14,708 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp630872368/tmp355207229/pig-0.17.0-core-h2.jar\n",
      "2021-01-29 14:45:14,732 [Thread-11] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:14,813 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp630872368/tmp-2098081043/automaton-1.11-8.jar\n",
      "2021-01-29 14:45:14,949 [Thread-13] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:15,111 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp630872368/tmp-2073067346/antlr-runtime-3.4.jar\n",
      "2021-01-29 14:45:15,226 [Thread-15] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:15,348 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp630872368/tmp-1615498902/joda-time-2.9.3.jar\n",
      "2021-01-29 14:45:15,591 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2021-01-29 14:45:15,670 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2021-01-29 14:45:15,679 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2021-01-29 14:45:15,681 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2021-01-29 14:45:15,912 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2021-01-29 14:45:15,976 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:15,989 [JobControl] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:16,031 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2021-01-29 14:45:16,045 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:16,310 [JobControl] INFO  org.apache.hadoop.mapreduce.JobResourceUploader - Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1611844877680_0010\n",
      "2021-01-29 14:45:16,334 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-01-29 14:45:16,391 [JobControl] INFO  org.apache.pig.builtin.PigStorage - Using PigTextInputFormat\n",
      "2021-01-29 14:45:16,594 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-01-29 14:45:16,595 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2021-01-29 14:45:16,653 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2021-01-29 14:45:16,718 [Thread-18] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:16,785 [Thread-20] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:16,821 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-01-29 14:45:17,786 [Thread-22] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:17,940 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1611844877680_0010\n",
      "2021-01-29 14:45:17,941 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2021-01-29 14:45:18,593 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2021-01-29 14:45:18,809 [JobControl] INFO  org.apache.hadoop.conf.Configuration - resource-types.xml not found\n",
      "2021-01-29 14:45:18,813 [JobControl] INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils - Unable to find 'resource-types.xml'.\n",
      "2021-01-29 14:45:19,119 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1611844877680_0010\n",
      "2021-01-29 14:45:19,336 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://hadoop:8088/proxy/application_1611844877680_0010/\n",
      "2021-01-29 14:45:19,337 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1611844877680_0010\n",
      "2021-01-29 14:45:19,337 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases station_ids_names,stations\n",
      "2021-01-29 14:45:19,337 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: stations[1,11],station_ids_names[-1,-1] C:  R: \n",
      "2021-01-29 14:45:19,367 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 0% complete\n",
      "2021-01-29 14:45:19,368 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0010]\n",
      "2021-01-29 14:45:51,778 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 16% complete\n",
      "2021-01-29 14:45:51,778 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0010]\n",
      "2021-01-29 14:45:54,791 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 33% complete\n",
      "2021-01-29 14:45:54,802 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:54,806 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:54,825 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:45:55,819 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:55,820 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:55,831 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:45:55,895 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2021-01-29 14:45:55,901 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:55,902 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:55,915 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:45:56,263 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2021-01-29 14:45:56,264 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2021-01-29 14:45:56,269 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2021-01-29 14:45:56,271 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Using reducer estimator: org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator\n",
      "2021-01-29 14:45:56,293 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.InputSizeReducerEstimator - BytesPerReducer=1000000000 maxReducers=999 totalInputFileSize=2204\n",
      "2021-01-29 14:45:56,299 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2021-01-29 14:45:56,300 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2021-01-29 14:45:56,343 [Thread-28] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:56,513 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp630872368/tmp-784746336/pig-0.17.0-core-h2.jar\n",
      "2021-01-29 14:45:56,552 [Thread-30] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:56,593 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp630872368/tmp-1329978407/automaton-1.11-8.jar\n",
      "2021-01-29 14:45:56,617 [Thread-32] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:56,657 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp630872368/tmp651641588/antlr-runtime-3.4.jar\n",
      "2021-01-29 14:45:56,710 [Thread-34] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:56,779 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp630872368/tmp-823359485/joda-time-2.9.3.jar\n",
      "2021-01-29 14:45:56,782 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2021-01-29 14:45:56,784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2021-01-29 14:45:56,784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2021-01-29 14:45:56,784 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2021-01-29 14:45:57,059 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2021-01-29 14:45:57,075 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:45:57,080 [JobControl] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:45:57,099 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:45:57,169 [JobControl] INFO  org.apache.hadoop.mapreduce.JobResourceUploader - Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1611844877680_0011\n",
      "2021-01-29 14:45:57,177 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-01-29 14:45:57,233 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-01-29 14:45:57,235 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2021-01-29 14:45:57,235 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2021-01-29 14:45:57,352 [Thread-36] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:57,466 [Thread-38] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:57,512 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-01-29 14:45:57,563 [Thread-40] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:45:57,604 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1611844877680_0011\n",
      "2021-01-29 14:45:57,605 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2021-01-29 14:45:57,620 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2021-01-29 14:45:57,923 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1611844877680_0011\n",
      "2021-01-29 14:45:57,946 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://hadoop:8088/proxy/application_1611844877680_0011/\n",
      "2021-01-29 14:45:57,950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1611844877680_0011\n",
      "2021-01-29 14:45:57,950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ordered\n",
      "2021-01-29 14:45:57,950 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ordered[5,10] C:  R: \n",
      "2021-01-29 14:46:32,530 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 50% complete\n",
      "2021-01-29 14:46:32,558 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0011]\n",
      "2021-01-29 14:46:45,620 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 66% complete\n",
      "2021-01-29 14:46:45,620 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0011]\n",
      "2021-01-29 14:46:48,646 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:46:48,647 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:46:48,698 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:46:49,224 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:46:49,244 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:46:49,277 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:46:49,483 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:46:49,493 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:46:49,500 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:46:49,599 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.MRScriptState - Pig script settings are added to the job\n",
      "2021-01-29 14:46:49,599 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - mapred.job.reduce.markreset.buffer.percent is not set, set to default 0.3\n",
      "2021-01-29 14:46:49,607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Reduce phase detected, estimating # of required reducers.\n",
      "2021-01-29 14:46:49,607 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting Parallelism to 1\n",
      "2021-01-29 14:46:49,608 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - This job cannot be converted run in-process\n",
      "2021-01-29 14:46:49,678 [Thread-46] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:50,041 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/pig-0.17.0-core-h2.jar to DistributedCache through /tmp/temp630872368/tmp-97009733/pig-0.17.0-core-h2.jar\n",
      "2021-01-29 14:46:50,084 [Thread-48] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:50,193 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/automaton-1.11-8.jar to DistributedCache through /tmp/temp630872368/tmp-974115221/automaton-1.11-8.jar\n",
      "2021-01-29 14:46:50,234 [Thread-50] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:50,301 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/antlr-runtime-3.4.jar to DistributedCache through /tmp/temp630872368/tmp-1343834174/antlr-runtime-3.4.jar\n",
      "2021-01-29 14:46:50,357 [Thread-52] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:50,447 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Added jar file:/opt/pig-0.17.0/lib/joda-time-2.9.3.jar to DistributedCache through /tmp/temp630872368/tmp1636753408/joda-time-2.9.3.jar\n",
      "2021-01-29 14:46:50,457 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.JobControlCompiler - Setting up single store job\n",
      "2021-01-29 14:46:50,458 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Key [pig.schematuple] is false, will not generate code.\n",
      "2021-01-29 14:46:50,465 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Starting process to move generated code to distributed cacche\n",
      "2021-01-29 14:46:50,466 [main] INFO  org.apache.pig.data.SchemaTupleFrontend - Setting key [pig.schematuple.classes] with classes to deserialize []\n",
      "2021-01-29 14:46:50,640 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 1 map-reduce job(s) waiting for submission.\n",
      "2021-01-29 14:46:50,668 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:46:50,669 [JobControl] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:46:50,706 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "2021-01-29 14:46:50,750 [JobControl] INFO  org.apache.hadoop.mapreduce.JobResourceUploader - Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1611844877680_0012\n",
      "2021-01-29 14:46:50,757 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2021-01-29 14:46:50,849 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2021-01-29 14:46:50,849 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths to process : 1\n",
      "2021-01-29 14:46:50,849 [JobControl] INFO  org.apache.pig.backend.hadoop.executionengine.util.MapRedUtil - Total input paths (combined) to process : 1\n",
      "2021-01-29 14:46:50,880 [Thread-54] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:50,959 [Thread-56] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:51,009 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2021-01-29 14:46:51,045 [Thread-58] INFO  org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:46:51,100 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1611844877680_0012\n",
      "2021-01-29 14:46:51,101 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Executing with tokens: []\n",
      "2021-01-29 14:46:51,114 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2021-01-29 14:46:51,491 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1611844877680_0012\n",
      "2021-01-29 14:46:51,522 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://hadoop:8088/proxy/application_1611844877680_0012/\n",
      "2021-01-29 14:46:51,527 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - HadoopJobId: job_1611844877680_0012\n",
      "2021-01-29 14:46:51,527 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Processing aliases ordered\n",
      "2021-01-29 14:46:51,528 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - detailed locations: M: ordered[5,10] C:  R: \n",
      "2021-01-29 14:47:31,286 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 83% complete\n",
      "2021-01-29 14:47:31,287 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0012]\n",
      "2021-01-29 14:47:48,818 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Running jobs are [job_1611844877680_0012]\n",
      "2021-01-29 14:47:51,850 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:51,851 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:51,873 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,053 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,053 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,061 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,180 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,181 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,188 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,277 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - 100% complete\n",
      "2021-01-29 14:47:52,390 [main] INFO  org.apache.pig.tools.pigstats.mapreduce.SimplePigStats - Script Statistics: \n",
      "\n",
      "HadoopVersion\tPigVersion\tUserId\tStartedAt\tFinishedAt\tFeatures\n",
      "3.2.1\t0.17.0\thadoop\t2021-01-29 14:45:13\t2021-01-29 14:47:52\tORDER_BY\n",
      "\n",
      "Success!\n",
      "\n",
      "Job Stats (time in seconds):\n",
      "JobId\tMaps\tReduces\tMaxMapTime\tMinMapTime\tAvgMapTime\tMedianMapTime\tMaxReduceTime\tMinReduceTime\tAvgReduceTime\tMedianReducetime\tAlias\tFeature\tOutputs\n",
      "job_1611844877680_0010\t1\t0\t10\t10\t10\t10\t0\t0\t0\t0\tstation_ids_names,stations\tMAP_ONLY\t\n",
      "job_1611844877680_0011\t1\t1\t13\t13\t13\t13\t8\t8\t8\t8\tordered\tSAMPLER\t\n",
      "job_1611844877680_0012\t1\t1\t16\t16\t16\t16\t15\t15\t15\t15\tordered\tORDER_BY\thdfs://hadoop:9000/user/hadoop/ordered,\n",
      "\n",
      "Input(s):\n",
      "Successfully read 70 records (5522 bytes) from: \"hdfs://hadoop:9000/user/hadoop/stations\"\n",
      "\n",
      "Output(s):\n",
      "Successfully stored 70 records (1846 bytes) in: \"hdfs://hadoop:9000/user/hadoop/ordered\"\n",
      "\n",
      "Counters:\n",
      "Total records written : 70\n",
      "Total bytes written : 1846\n",
      "Spillable Memory Manager spill count : 0\n",
      "Total bags proactively spilled: 0\n",
      "Total records proactively spilled: 0\n",
      "\n",
      "Job DAG:\n",
      "job_1611844877680_0010\t->\tjob_1611844877680_0011,\n",
      "job_1611844877680_0011\t->\tjob_1611844877680_0012,\n",
      "job_1611844877680_0012\n",
      "\n",
      "\n",
      "2021-01-29 14:47:52,394 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,398 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,403 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,467 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,468 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,480 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,522 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,525 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,539 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:52,722 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:52,725 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:52,791 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,030 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:53,032 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:53,044 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,087 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:53,088 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:53,094 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,306 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:53,314 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:53,333 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,450 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:53,465 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:53,509 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,581 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at hadoop/172.17.0.2:8032\n",
      "2021-01-29 14:47:53,582 [main] INFO  org.apache.hadoop.yarn.client.AHSProxy - Connecting to Application History server at hadoop/172.17.0.2:10200\n",
      "2021-01-29 14:47:53,593 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2021-01-29 14:47:53,651 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
      "2021-01-29 14:47:53,734 [main] INFO  org.apache.pig.Main - Pig script completed in 2 minutes, 51 seconds and 129 milliseconds (171129 ms)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/src\n",
    "\n",
    "cat > list_stations.pig << EOF\n",
    "stations = LOAD 'stations' USING PigStorage(',') AS \n",
    "(station_id:int, name:chararray, lat:float, long:float, \n",
    " dockcount:int, landmark:chararray, installation:chararray);\n",
    "station_ids_names = FOREACH stations GENERATE station_id, name;\n",
    "ordered = ORDER station_ids_names BY name;\n",
    "STORE ordered INTO 'ordered';\n",
    "EOF\n",
    "\n",
    "# run using mapreduce\n",
    "pig -x mapreduce -f list_stations.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\t2nd at Folsom\n",
      "64\t2nd at South Park\n",
      "61\t2nd at Townsend\n",
      "57\t5th at Howard\n",
      "5\tAdobe on Almaden\n",
      "14\tArena Green / SAP Center\n",
      "56\tBeale at Market\n",
      "82\tBroadway St at Battery St\n",
      "36\tCalifornia Ave Caltrain Station\n",
      "32\tCastro Street and El Camino Real\n",
      "72\tCivic Center BART (7th at Market)\n",
      "41\tClay at Battery\n",
      "45\tCommercial at Montgomery\n",
      "37\tCowper at University\n",
      "42\tDavis at Jackson\n",
      "54\tEmbarcadero at Bryant\n",
      "51\tEmbarcadero at Folsom\n",
      "60\tEmbarcadero at Sansome\n",
      "48\tEmbarcadero at Vallejo\n",
      "30\tEvelyn Park and Ride\n",
      "21\tFranklin at Maple\n",
      "59\tGolden Gate at Polk\n",
      "73\tGrant Avenue at Columbus Avenue\n",
      "50\tHarry Bridges Plaza (Ferry Building)\n",
      "63\tHoward at 2nd\n",
      "9\tJapantown\n",
      "11\tMLK Library\n",
      "67\tMarket at 10th\n",
      "76\tMarket at 4th\n",
      "77\tMarket at Sansome\n",
      "75\tMechanics Plaza (Market at Battery)\n",
      "83\tMezes Park\n",
      "28\tMountain View Caltrain Station\n",
      "27\tMountain View City Hall\n",
      "34\tPalo Alto Caltrain Station\n",
      "38\tPark at Olive\n",
      "7\tPaseo de San Antonio\n",
      "47\tPost at Kearney\n",
      "39\tPowell Street BART\n",
      "71\tPowell at Post (Union Square)\n",
      "22\tRedwood City Caltrain Station\n",
      "26\tRedwood City Medical Center\n",
      "24\tRedwood City Public Library\n",
      "33\tRengstorff Avenue / California Street\n",
      "84\tRyland Park\n",
      "16\tSJSU - San Salvador at 9th\n",
      "12\tSJSU 4th at San Carlos\n",
      "29\tSan Antonio Caltrain Station\n",
      "31\tSan Antonio Shopping Center\n",
      "70\tSan Francisco Caltrain (Townsend at 4th)\n",
      "69\tSan Francisco Caltrain 2 (330 Townsend)\n",
      "58\tSan Francisco City Hall\n",
      "10\tSan Jose City Hall\n",
      "3\tSan Jose Civic Center\n",
      "2\tSan Jose Diridon Caltrain Station\n",
      "23\tSan Mateo County Center\n",
      "6\tSan Pedro Square\n",
      "8\tSan Salvador at 1st\n",
      "80\tSanta Clara County Civic Center\n",
      "4\tSanta Clara at Almaden\n",
      "66\tSouth Van Ness at Market\n",
      "49\tSpear at Folsom\n",
      "13\tSt James Park\n",
      "25\tStanford in Redwood City\n",
      "74\tSteuart at Market\n",
      "55\tTemporary Transbay Terminal (Howard at Beale)\n",
      "65\tTownsend at 7th\n",
      "35\tUniversity and Emerson\n",
      "46\tWashington at Kearney\n",
      "68\tYerba Buena Center of the Arts (3rd @ Howard)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 14:48:50,236 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "hdfs dfs -cat ordered/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount using Pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a, able, about, across, after, all, almost, also, am, among, an, and, any, are, as, at, be, because, been, but, by, can, cannot, could, dear, did, do, does, either, else, ever, every, for, from, get, got, had, has, have, he, her, hers, him, his, how, however, i, if, in, into, is, it, its, just, least, let, like, likely, may, me, might, most, must, my, neither, no, nor, not, of, off, often, on, only, or, other, our, own, rather, said, say, says, she, should, since, so, some, than, that, the, their, them, then, there, these, they, this, tis, to, too, twas, us, wants, was, we, were, what, when, where, which, while, who, whom, why, will, with, would, yet, you, your"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 14:49:33,526 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n",
      "2021-01-29 14:49:39,133 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/datasets\n",
    "wget -q -c https://tinyurl.com/y68jxy7f -O stop-word-list.csv\n",
    "hdfs dfs -mkdir stopwords\n",
    "hdfs dfs -put stop-word-list.csv stopwords\n",
    "hdfs dfs -cat stopwords/stop-word-list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in grunt\n",
    "\n",
    "```\n",
    "source /opt/envvars.sh\n",
    "cd /opt/datasets\n",
    "pig -x mapreduce 2> /dev/null\n",
    "```\n",
    "\n",
    "```\n",
    "-- List HDFS content\n",
    "fs -ls\n",
    "fs -ls shakespeare\n",
    "\n",
    "-- Job name to appear in YARN\n",
    "SET job.name 'Word Count in Pig';\n",
    "\n",
    "-- Load shakespeare dataset\n",
    "shakespeare = LOAD 'shakespeare' AS (lineoftext:chararray);\n",
    "\n",
    "-- Load stopwords\n",
    "stopwords = LOAD 'stopwords' USING PigStorage() AS (stopword:chararray);\n",
    "\n",
    "-- Create bag of words\n",
    "words = FOREACH shakespeare GENERATE\n",
    "        FLATTEN(TOKENIZE(REPLACE(LOWER(TRIM(lineoftext)),\n",
    "        '[\\\\p{Punct},\\\\p{Cntrl}]',''))) AS word;\n",
    "\n",
    "-- Remove empty words\n",
    "realwords = FILTER words BY SIZE(word) > 0;\n",
    "\n",
    "-- Create bag of stop words\n",
    "flattened_stopwords = FOREACH stopwords GENERATE\n",
    "       FLATTEN(TOKENIZE(stopword)) AS stopword;\n",
    "\n",
    "-- Associate words with respective stop words\n",
    "right_joined = JOIN flattened_stopwords\n",
    "               BY stopword RIGHT OUTER,\n",
    "               realwords BY word;\n",
    "\n",
    "-- Remove stop words\n",
    "meaningful_words = FILTER right_joined BY\n",
    "          (flattened_stopwords::stopword IS NULL);\n",
    "\n",
    "-- Retrieve remaining words\n",
    "shakespeare_real_words = FOREACH meaningful_words\n",
    "          GENERATE realwords::word AS word;\n",
    "\n",
    "-- Group words\n",
    "grouped = GROUP shakespeare_real_words BY word;\n",
    "\n",
    "-- Count grouped words\n",
    "counted = FOREACH grouped GENERATE group AS word,\n",
    "          COUNT(shakespeare_real_words) AS wordcount;\n",
    "\n",
    "-- Sort bag in descending order\n",
    "ordered = ORDER counted BY wordcount DESC;\n",
    "\n",
    "-- Select 30 first words\n",
    "top30 = LIMIT ordered 30;\n",
    "\n",
    "-- Store output\n",
    "STORE top30 INTO 'shakespeare_top30';\n",
    "\n",
    "-- Show output from HDFS\n",
    "fs -cat shakespeare_top30/*\n",
    "\n",
    "-- Exit\n",
    "QUIT;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
